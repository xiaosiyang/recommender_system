{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from blob import blobConn\n",
    "from sklearn.decomposition import NMF\n",
    "from scipy import sparse\n",
    "from sklearn.metrics import mean_squared_error\n",
    "path = \"/Users/yang_home/Documents/learning/AI_dev/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "385\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>session_start</th>\n",
       "      <th>session_size</th>\n",
       "      <th>click_article_id</th>\n",
       "      <th>click_timestamp</th>\n",
       "      <th>click_environment</th>\n",
       "      <th>click_deviceGroup</th>\n",
       "      <th>click_os</th>\n",
       "      <th>click_country</th>\n",
       "      <th>click_region</th>\n",
       "      <th>click_referrer_type</th>\n",
       "      <th>day_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93863</td>\n",
       "      <td>1507865792177843</td>\n",
       "      <td>1507865792000</td>\n",
       "      <td>2</td>\n",
       "      <td>96210</td>\n",
       "      <td>1507865832925</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93863</td>\n",
       "      <td>1507865792177843</td>\n",
       "      <td>1507865792000</td>\n",
       "      <td>2</td>\n",
       "      <td>158094</td>\n",
       "      <td>1507865862925</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>294036</td>\n",
       "      <td>1507865795185844</td>\n",
       "      <td>1507865795000</td>\n",
       "      <td>2</td>\n",
       "      <td>20691</td>\n",
       "      <td>1507865819095</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>294036</td>\n",
       "      <td>1507865795185844</td>\n",
       "      <td>1507865795000</td>\n",
       "      <td>2</td>\n",
       "      <td>96210</td>\n",
       "      <td>1507865849095</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77136</td>\n",
       "      <td>1507865796257845</td>\n",
       "      <td>1507865796000</td>\n",
       "      <td>2</td>\n",
       "      <td>336245</td>\n",
       "      <td>1507866133178</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id        session_id  session_start session_size click_article_id  \\\n",
       "0   93863  1507865792177843  1507865792000            2            96210   \n",
       "1   93863  1507865792177843  1507865792000            2           158094   \n",
       "2  294036  1507865795185844  1507865795000            2            20691   \n",
       "3  294036  1507865795185844  1507865795000            2            96210   \n",
       "4   77136  1507865796257845  1507865796000            2           336245   \n",
       "\n",
       "  click_timestamp click_environment click_deviceGroup click_os click_country  \\\n",
       "0   1507865832925                 4                 3        2             1   \n",
       "1   1507865862925                 4                 3        2             1   \n",
       "2   1507865819095                 4                 3       20             1   \n",
       "3   1507865849095                 4                 3       20             1   \n",
       "4   1507866133178                 4                 3        2             1   \n",
       "\n",
       "  click_region click_referrer_type  day_number  \n",
       "0           21                   2          12  \n",
       "1           21                   2          12  \n",
       "2            9                   2          12  \n",
       "3            9                   2          12  \n",
       "4           25                   2          12  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data\n",
    "filenames = glob.glob(path + 'news-portal-user-interactions-by-globocom/clicks/*.csv' )\n",
    "#filenames = glob.glob(path + 'news-portal-user-interactions-by-globocom/clicks/clicks_hour_[0-1][0-9][0-9].csv' )\n",
    "print(len(filenames))\n",
    "click = pd.DataFrame()\n",
    "for file in filenames:\n",
    "    f = pd.read_csv(file)\n",
    "    # add day number, 16 days of data in total\n",
    "    f['day_number'] = int(file.split('_')[-1].split('.')[0]) // 24\n",
    "    click = pd.concat([click, f], axis = 0)\n",
    "click.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmse(actual, pred):\n",
    "    \"\"\"Pred and actual are arrays\n",
    "    \"\"\"\n",
    "    actual1 = actual[actual.nonzero()].flatten() # Ignore zero terms\n",
    "    pred1 = pred[actual.nonzero()].flatten()     # Ignore zero terms\n",
    "\n",
    "    return np.sqrt(mean_squared_error(actual1, pred1))\n",
    "\n",
    "def get_sparse_matrix(data, shape=None):\n",
    "    \"\"\"data is the user article click dataframe\"\"\"\n",
    "    row = data.iloc[:,0].values\n",
    "    col = data.iloc[:,1].values\n",
    "    val = data.iloc[:,2].values\n",
    "    #n_user = len(data.user_id.unique())\n",
    "    #n_article = len(data.click_article_id.unique())\n",
    "    max_user_idx = max(row)\n",
    "    max_article_idx = max(col)\n",
    "    if not shape:\n",
    "        sparse_mat = sparse.csc_matrix((val, (row, col)), shape=(max_user_idx+1, max_article_idx+1))\n",
    "\n",
    "    else:\n",
    "        sparse_mat = sparse.csc_matrix((val, (row, col)), shape=(shape[0], shape[1]))\n",
    "\n",
    "    return sparse_mat\n",
    "\n",
    "\n",
    "def NMFModel(R, **params_NMF):\n",
    "    \"\"\"R is sparse matrix\"\"\"\n",
    "    model = NMF(**params_NMF)\n",
    "    W = model.fit_transform(R)\n",
    "    H = model.components_\n",
    "    R_hat = np.dot(W,H)\n",
    "    #R_hat_sparse = sparse.csc_matrix(R_hat)\n",
    "    return R_hat, H, model\n",
    "\n",
    "\n",
    "def get_interaction(raw_data):\n",
    "    user_article_click = raw_data.groupby(['user_id','click_article_id'],as_index=False).size()\n",
    "    #user_article_click.rename(columns = {'size':'click'},inplace=True)\n",
    "    user_article_click['click']=(user_article_click['size'] >=1).astype(int)\n",
    "    return user_article_click[['user_id','click_article_id','click']]\n",
    "\n",
    "def sample_by_index(data, user_limit, article_limit):\n",
    "    ''' the click data is too big\n",
    "    this function is to get a portion of users and articles to train the model\n",
    "    Params:\n",
    "    data: user article click interaction\n",
    "    user_limit: user_id upper limit. (user_id start from 0 to 323896)\n",
    "    article_limit: article_id upper limit. (article_id start from 0 to 300k)\n",
    "    '''\n",
    "    df = data[(data['user_id']<=user_limit) & (data['click_article_id']<=article_limit)]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape is (1106, 3), test shape is (677, 3)\n",
      "(10000, 10000)\n",
      "(10000, 10000)\n"
     ]
    }
   ],
   "source": [
    "train0, test0 = click[click['day_number']<=10], click[click['day_number']>10]\n",
    "# further select user and article to reduce computation time\n",
    "max_user = 9999\n",
    "max_article = 9999\n",
    "train1, test1 = sample_by_index(train0,max_user,max_article), sample_by_index(test0,max_user,max_article)\n",
    "\n",
    "train = get_interaction(train1)\n",
    "test = get_interaction(test1)\n",
    "print(f'train shape is {train.shape}, test shape is {test.shape}')\n",
    "\n",
    "R_train = get_sparse_matrix(train,shape=[max_user+1, max_article+1])\n",
    "R_test = get_sparse_matrix(test, shape=[max_user+1, max_article+1])\n",
    "\n",
    "print(R_train.toarray().shape)\n",
    "print(R_test.toarray().shape)\n",
    "\n",
    "params_NMF = {\n",
    "                'n_components' : 20,\n",
    "                #'alpha_W' : 0.01,\n",
    "                'l1_ratio' : 0, \n",
    "                'max_iter' : 200\n",
    "            }\n",
    "\n",
    "R_pred, H, model = NMFModel(R_train, **params_NMF)\n",
    "\n",
    "perf = get_rmse(R_test.toarray(), R_pred)\n",
    "print(perf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_fold(interaction_df,max_user, max_article, fold):\n",
    "    mid_user = max_user // 2\n",
    "    mid_article = max_article// 2\n",
    "    idx_dict = {\n",
    "                0: [[0,mid_user],[0, mid_article]],\n",
    "                1: [[0,mid_user],[mid_article, max_article + 1]],\n",
    "                2: [[mid_user, max_user + 1], [0, mid_article]],\n",
    "                3: [[mid_user, max_user + 1], [mid_article, max_article + 1]]\n",
    "    }\n",
    "\n",
    "    idx = idx_dict[fold]\n",
    "\n",
    "    test = interaction_df[(interaction_df['user_id']>= idx[0][0]) \\\n",
    "                          & (interaction_df['user_id'] < idx[0][1]) \\\n",
    "                          & (interaction_df['click_article_id']>= idx[1][0]) \\\n",
    "                          & (interaction_df['click_article_id'] < idx[1][1])]\n",
    "    train = interaction_df[(interaction_df['user_id'] < idx[0][0]) \\\n",
    "                           | (interaction_df['user_id'] >= idx[0][1]) \\\n",
    "                            | (interaction_df['click_article_id'] < idx[1][0]) \\\n",
    "                            | (interaction_df['click_article_id'] >= idx[1][1])]\n",
    "    return train, test\n",
    "\n",
    "def grid_search_train(params, max_user, max_article):\n",
    "    train0, test0 = click[click['day_number']<=10], click[click['day_number']>10]\n",
    "\n",
    "    train1, test1 = sample_by_index(train0,max_user,max_article), sample_by_index(test0,max_user,max_article)\n",
    "\n",
    "    train = get_interaction(train1)\n",
    "    test = get_interaction(test1)\n",
    "    print(f'train shape is {train.shape}, test shape is {test.shape}')\n",
    "\n",
    "\n",
    "\n",
    "    grid_search_res = []\n",
    "    n_round = 0\n",
    "    # columns: max_user, max_article, n_compoment, alpha, l1_ratio, max_iter, rmse\n",
    "    for n_component in params['n_components']:\n",
    "        for alpha_W in params['alpha_W']:\n",
    "            for l1_ratio in params['l1_ratio']:\n",
    "                for max_iter in params['max_iter']:\n",
    "                    n_round += 1\n",
    "                    print(f'round {n_round}')\n",
    "                    params_gs = {\n",
    "                                        'n_components' : n_component,\n",
    "                                        'init' : 'random', \n",
    "                                        'random_state' : 0, \n",
    "                                        'alpha_W' : alpha_W,\n",
    "                                        'l1_ratio' : l1_ratio,\n",
    "                                        'max_iter' : max_iter\n",
    "                                        }\n",
    "                    # genereate n fold for train and cross validation\n",
    "                    err = []\n",
    "                    for i in range(4):\n",
    "                        print(f'fold {i}')\n",
    "                        X, Y = cv_fold(train, max_user, max_article,i)\n",
    "                        R_X = get_sparse_matrix(X,shape=[max_user+1, max_article+1])\n",
    "                        R_Y = get_sparse_matrix(Y, shape=[max_user+1, max_article+1])\n",
    "\n",
    "                        R_hat, estimator = NMFModel(R_X, **params_gs)\n",
    "\n",
    "                        rmse = get_rmse(R_Y.toarray(), R_hat)\n",
    "                        err.append(rmse)\n",
    "                    avg_rmse = sum(err)/4\n",
    "                    print(f'this is average rmse: {avg_rmse}')\n",
    "                        \n",
    "                    grid_search_res.append([max_user, max_article, \n",
    "                            params_gs['n_components'], params_gs['alpha_W'], params_gs['l1_ratio'], params_gs['max_iter'], \n",
    "                            avg_rmse] + err)\n",
    "        \n",
    "    gs_df = pd.DataFrame(grid_search_res, columns=['max_user','max_article',\n",
    "                                      'n_components','alpha_W','l1_ratio','max_iter', \n",
    "                                      'avg_rmse','fold_1_rmse','fold_2_rmse','fold_3_rmse','fold_4_rmse'])\n",
    "    best_params = gs_df.sort_values(by='avg_rmse')\n",
    "\n",
    "    return best_params, gs_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape is (15676, 3), test shape is (6570, 3)\n",
      "round 1\n",
      "fold 0\n",
      "fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yang_home/Documents/learning/AI_dev/recommender_system/venv/lib/python3.9/site-packages/sklearn/decomposition/_nmf.py:1665: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 2\n",
      "fold 3\n",
      "this is average rmse: 0.9960317485571636\n",
      "round 2\n",
      "fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yang_home/Documents/learning/AI_dev/recommender_system/venv/lib/python3.9/site-packages/sklearn/decomposition/_nmf.py:1665: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yang_home/Documents/learning/AI_dev/recommender_system/venv/lib/python3.9/site-packages/sklearn/decomposition/_nmf.py:1665: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yang_home/Documents/learning/AI_dev/recommender_system/venv/lib/python3.9/site-packages/sklearn/decomposition/_nmf.py:1665: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yang_home/Documents/learning/AI_dev/recommender_system/venv/lib/python3.9/site-packages/sklearn/decomposition/_nmf.py:1665: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is average rmse: 0.9973239730110631\n"
     ]
    }
   ],
   "source": [
    "# Grid search train\n",
    "params = {\n",
    "                'n_components' : [50, 100],\n",
    "                'alpha_W' : [0],\n",
    "                'l1_ratio' : [0], \n",
    "                'max_iter' : [200]\n",
    "            }\n",
    "\n",
    "\n",
    "best_params, record_df = grid_search_train(params, 5000, 100000)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_user</th>\n",
       "      <th>max_article</th>\n",
       "      <th>n_components</th>\n",
       "      <th>alpha_W</th>\n",
       "      <th>l1_ratio</th>\n",
       "      <th>max_iter</th>\n",
       "      <th>avg_rmse</th>\n",
       "      <th>fold_1_rmse</th>\n",
       "      <th>fold_2_rmse</th>\n",
       "      <th>fold_3_rmse</th>\n",
       "      <th>fold_4_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>100000</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>0.996032</td>\n",
       "      <td>0.994264</td>\n",
       "      <td>0.997619</td>\n",
       "      <td>0.994784</td>\n",
       "      <td>0.997460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5000</td>\n",
       "      <td>100000</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>0.997324</td>\n",
       "      <td>0.996156</td>\n",
       "      <td>0.998340</td>\n",
       "      <td>0.996420</td>\n",
       "      <td>0.998379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_user  max_article  n_components  alpha_W  l1_ratio  max_iter  avg_rmse  \\\n",
       "0      5000       100000            50        0         0       200  0.996032   \n",
       "1      5000       100000           100        0         0       200  0.997324   \n",
       "\n",
       "   fold_1_rmse  fold_2_rmse  fold_3_rmse  fold_4_rmse  \n",
       "0     0.994264     0.997619     0.994784     0.997460  \n",
       "1     0.996156     0.998340     0.996420     0.998379  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_params = {\n",
    "                'n_components' :50,\n",
    "                'alpha_W' : 0,\n",
    "                'l1_ratio' : 0, \n",
    "                'max_iter' : 200\n",
    "            }\n",
    "max_user = 10000\n",
    "max_article = 100000\n",
    "train0, test0 = click[click['day_number']<=10], click[click['day_number']>10]\n",
    "\n",
    "train1, test1 = sample_by_index(train0,max_user,max_article), sample_by_index(test0,max_user,max_article)\n",
    "\n",
    "train = get_interaction(train1)\n",
    "test = get_interaction(test1)\n",
    "R_train = get_sparse_matrix(train,shape=[max_user+1, max_article+1])\n",
    "#R_test = get_sparse_matrix(test, shape=[max_user+1, max_article+1])\n",
    "#R_pred, estimator = NMFModel(R_train, **opt_params)\n",
    "#performance = get_rmse(R_test.toarray(),R_pred)\n",
    "#performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(path + 'recommender_system/model/NMF_sparse2.npy', R_pred_sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "def save_model(model):\n",
    "    with open(path + 'recommender_system/model/NMF_model_v1.pickle','wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "        f.close()\n",
    "# load model\n",
    "def load_mdoel(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "        f.close()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make prediction for user with history\n",
    "all_user_article_interaction = click.groupby(['user_id','click_article_id'],as_index=False).size()\n",
    "all_user_article_interaction.rename(columns = {'size':'click'},inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9999, 3329, 3336, 3335, 3334])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new user\n",
    "from model import NMF_recommendation\n",
    "\n",
    "new_id = 322482\n",
    "xx = NMF_recommendation(all_user_article_interaction, model,H,R_pred, new_id)\n",
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>click_article_id</th>\n",
       "      <th>click</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>10</td>\n",
       "      <td>5341</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>10</td>\n",
       "      <td>7744</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>23</td>\n",
       "      <td>2137</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>24</td>\n",
       "      <td>5341</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>26</td>\n",
       "      <td>4658</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2949745</th>\n",
       "      <td>322482</td>\n",
       "      <td>5349</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2950173</th>\n",
       "      <td>322666</td>\n",
       "      <td>1973</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2950560</th>\n",
       "      <td>322829</td>\n",
       "      <td>5583</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2950561</th>\n",
       "      <td>322829</td>\n",
       "      <td>5595</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2950588</th>\n",
       "      <td>322842</td>\n",
       "      <td>1973</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20182 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  click_article_id  click\n",
       "248           10              5341      1\n",
       "249           10              7744      1\n",
       "669           23              2137      1\n",
       "720           24              5341      1\n",
       "872           26              4658      1\n",
       "...          ...               ...    ...\n",
       "2949745   322482              5349      1\n",
       "2950173   322666              1973      1\n",
       "2950560   322829              5583      1\n",
       "2950561   322829              5595      1\n",
       "2950588   322842              1973      1\n",
       "\n",
       "[20182 rows x 3 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_user_article_interaction[all_user_article_interaction['click_article_id']<10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NMF_recommendation(data, estimator, H, R_pred, user_id):\n",
    "    \"\"\"R_pred is array\n",
    "        data is interaction data generated already\n",
    "    \"\"\"\n",
    "    user_id = int(user_id)\n",
    "    if user_id < R_pred.shape[0]:\n",
    "        # user in prediction matrix\n",
    "        sort_article = np.argsort(R_pred[user_id])[::-1][:5]\n",
    "    else:\n",
    "        # user not in prediction matrix (0-10000)\n",
    "        # convert click history to preference matrix, use existing model\n",
    "        history = np.full((1,R_pred.shape[1]),0)\n",
    "        user_df = data[(data['user_id'] == user_id) & (data['click_article_id']<=R_pred.shape[1])]\n",
    "        print(user_df.head())\n",
    "        if len(user_df) == 0:\n",
    "            #completely new with no click history\n",
    "            return '404'\n",
    "        indexs = user_df.click_article_id.values\n",
    "        history[0][indexs] = 1\n",
    "        #new_R = np.concatenate((R_train.toarray(),history),axis = 0)\n",
    "        new_record = estimator.transform(history)\n",
    "        new_R_hat = np.dot(new_record,H)\n",
    "        sort_article = np.argsort(new_R_hat[-1])[::-1][:5]\n",
    "\n",
    "    return sort_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100001)\n",
      "(10001, 100001)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([30970,  2647, 58565, 36080, 95977])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_test = NMF_recommendation(all_user_article_interaction,estimator, R_pred, 12345)\n",
    "rec_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def cv_matrix(X, fold):\n",
    "    '''\n",
    "    Given a matrix X, the function creates 4 sets of train + test matrices\n",
    "    where each train matrix is masked with zeros in 0.25 of the values, and the\n",
    "    test matrix is masked zeros in 0.75 of them.\n",
    "    X - numpy array\n",
    "    fold - is an integer from 0-3.\n",
    "    Returns the masked data and also the masks for train and test\n",
    "    '''\n",
    "    # Create a dict with the slicing indices\n",
    "    rows = X.shape[0]\n",
    "    cols = X.shape[1]\n",
    "    mid_rows = int(rows/2)\n",
    "    mid_cols = int(cols/2)\n",
    "    \n",
    "    idx_dict = {\n",
    "                0: [[0,mid_rows],[0, mid_cols]],\n",
    "                1: [[0,mid_rows],[mid_cols, cols]],\n",
    "                2: [[mid_rows, rows], [0, mid_cols]],\n",
    "                3: [[mid_rows, rows], [mid_cols, cols]]\n",
    "    }\n",
    "    \n",
    "    idexes = idx_dict[fold]\n",
    "    # Create masks\n",
    "    train_mask = np.full((rows, cols), 1)\n",
    "    train_mask[idexes[0][0]:idexes[0][1], idexes[1][0]:idexes[1][1]] = 0\n",
    "    test_mask = 1 - train_mask\n",
    "    \n",
    "    \n",
    "    # Create X_train\n",
    "    X_train = X.copy()\n",
    "    X_train[train_mask==0] = 0\n",
    "    \n",
    "    # Create X_test\n",
    "    X_test = X.copy()\n",
    "    X_test[train_mask==1] = 0\n",
    "        \n",
    "    return X_train, X_test, train_mask, test_mask   \n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2e14c3c89239b12f9071f212020d16921e33c93a6ab4c8259b61c4db77f97a71"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
